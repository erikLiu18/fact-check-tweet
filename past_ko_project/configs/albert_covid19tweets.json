{
    "data_param": {
        "dataset": "time_sorted",
        "max_data_size": -1,
        "batch_size": 32,
        "data_root": "./data",
        "train_datapath": "1-2020",
        "val_datapath": "",
        "test_datapath": "12-2020",
        "num_classes": 2,
        "filter_long_text": true
    },
    "model": "albert",
    "tokenizer": "albert-base-v2",
    "model_param": {
        "vocab_size": 30000,
        "embedding_size": 128,
        "hidden_size": 768,
        "num_hidden_layers": 12,
        "num_hidden_groups": 1,
        "num_attention_heads": 12,
        "intermediate_size": 3072,
        "inner_group_num": 1,
        "hidden_act": "gelu",
        "hidden_dropout_prob": 0,
        "attention_probs_dropout_prob": 0,
        "max_position_embeddings": 512,
        "type_vocab_size": 2,
        "initializer_range": 0.02,
        "layer_norm_eps": 1.0e-12,
        "classifier_dropout_prob": 0.1
    },
    "trainer_param": {
        "epochs": 10,
        "val_epochs": 1,
        "loss_func": "cross_entropy",
        "metric": "acc",
        "optimizer": "AdamW",
        "optimizer_param": {
            "lr": 5.0e-5,
            "eps": 1.0e-6,
            "weight_decay": 0.0005
        }
    }
}
